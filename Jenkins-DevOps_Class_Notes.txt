0. Introduction of DevOps

=====================================================================================================================================================================
1. 6-10-24 Installation Jenkins and EC2 instances in AWS.
 - Create Account in GITHUB, GITEA & GITLAB
 - Launch one instance and give name = Jenkins and download key.
 - Then Open this instance switch to root using command "sudo -i"
 - Then go to Jenkins website then select Redhat Installation link.
 - Then copy commands and paste in Jenkins server, then install and check status.

sudo wget -o /etc/yum.repos.d/jenkins.repo https://pkg.jenkins.io/redhat-stable/jenkins.repo

sudo cpa import https://pkg.jenkins.io/redhat-stable/jenkins.io-2023.key

yum install fontconfig java-17-openjdk

java -version

cd /etc/yum.repos.d/ --> To check repo

systemctl start jenkins 
systemctl enable jenkins
systemctl status jenkins

- And check in browser with http://IP:8080
- And Open port in Security group in AWS.
=====================================================================================================================================================================

=====================================================================================================================================================================
2. 13-10-24 
 
Required two instances 
   1. One EC2 for Webserver Nginx 
   2. One EC2 for Jenkins Server 
   3. GitLab ACC 
In instances select t2.micro, create new key pair, auto assigned IP show be enabled, select second option of AMI(Amazon Machine Image).

Select the instances > Go to Security tab > click the security group ID > Go to Inbound Rule = HTTP.  Port=80.  0.0.0.0 > Save

Then Launch Machine or use Putty through using Public IP.
CMD
sudo -i    #Switch to root user
yum update -y    # To install Nginx
yum install nginx* -y
# yum install amazon-linux-extra 
amazon-linux-extra install nginx 
# amazon-linux-extra install epl -y

systemctl restart nginx 
systemctl enable nginx 
curl ifconfig.me # To check live IP OR check in Instances public IP.

http://IP  ---> Search in browser and get nginx page and should be 80 port open Security-Group in AWS.

# Nginx Default Path & Port  -- 80 PORT TCP
ls -d /usr/share/nginx/html/
cd /usr/share/nginx/html/
ls
mv index.html index.html.org
echo "THIS IS MY 1st PAGE" > index.html

# For Apache /var/www/html/

# Create Account in GITHUB and create new Repo name = anon-ecommerce-website.
Click Code and copy HTTP link. ---> To pull code from Git OR GitClone
- Firstly install Git in Nginx Server.
sudo -i
yum install git -y
#git clone <pull request URL>  --> Get Clone folder in /html/
git clone HTTP Link
ls 
cd anon-ecommerce-website/
ls
l.
http://IP/anon-ecommerce-website/  --> To search in browser  18.218.150.145

# Go to Fork > Select Import Repo > paste link and get Repo (https://github.com/codewithsadee/anon-ecommerce-website.git)

# Launch new instance for Jenkins-Server SELECT t3.micro 
JENKINs    INSTALLATION

yum install -y java-17-amazon-corretto
  
  
wget -O /etc/yum.repos.d/jenkins.repo http://pkg.jenkins.io/redhat/jenkins.repo
rpm --import https://pkg.jenkins.io/redhat/jenkins.io.key
yum install jenkins -y

-------
vim /etc/sysconfig/jenkins >>

# Jenkins configuration

# Default Jenkins home directory
JENKINS_HOME="/var/lib/jenkins"

# Default Jenkins port
JENKINS_PORT="8080"

# Jenkins log directory
JENKINS_LOG="/var/log/jenkins"

# Java options (adjust memory limits if needed)
JENKINS_JAVA_OPTIONS="-Djava.awt.headless=true -Xmx512m"

# Path to Java
JAVA_HOME=/usr/lib/jvm/java-17-amazon-corretto

# Jenkins WAR file
JENKINS_WAR="/usr/lib/jenkins/jenkins.war"

# Additional Jenkins arguments
JENKINS_ARGS=""


systemctl restart  jenkins
systemctl enable jenkins

http://<Serverip>:8080
---------------
=====================================================================================================================================================================

=====================================================================================================================================================================
3. 20-10-24

- Launch new instance for Jenkins 
Name : Jenkins-Server-1
Amazon Linux 2 AMI (HVM)
Type : t3.micro
Add inbound rule in SG Port-8080
sudo -i
yum install -y java-17-amazon-corretto
wget -O /etc/yum.repos.d/jenkins.repo http://pkg.jenkins.io/redhat/jenkins.repo
# rpm --import https://pkg.jenkins.io/redhat/jenkins.io.key  --> Only use if gives errors while installations
yum install jenkins -y
yum install git -y
systemctl start jenkins 
systemctl enable jenkins
systemctl status jenkins

https://IP:8080 ---> To search Jenkins in browser.
# If Jenkins not installed follow this steps.
cd /etc/yum.repo.d/
#cat jenkins.repo  --> In this "gpgcheck=0" shoulde be 0 for install purpose, if only it give errors change this and revert this after use. 

http://IP:8080
--> /var/lib/jenkins/secrets/initialAdminPassword  # In this path copy and paste in the browser for Authentication.
cat /var/lib/jenkins/secrets/initialAdminPassword

# GITHUB copying others repo in our Git
Seclect "+" To import Repo from others --> Paste URL(https://github.com/codewithsadee/anon-ecommerce-website.git), Your Username of GIT,GIT PW. Give Repository Name= Econ-Web-Ani

# Customize Jenkins --> Insatlled Suggested Plugins --> 
admin, admin --> Save & Contuine --> Save & Finish
# New Item --> Give name = Sample-Ecom-Project -->Select = Freestyle project --> Ok
# Description = My first project --> Select Check Box = GitHub project = Paste Path of Repo from browser search box
--> Scorce Code Management(SCM) = Git, GitURL = HTTP(https://github.com/... .git) ---> Branch = /master
--> Go to Git New Repo and copy HTTP from our Git-Repo and paste in Git Section
#--> Build Triggers = Select = GitHub hok tigger fot GITscm polling
---> Apply --> Save

#CD
Now communicate Nginx server to Jenkins
Install Nginx webserver
rpm -qa | grep -i nginx
Delete existing code in html-path folder rm -rf *

# Insatall New Plugins
--> Go to Dashboard of Jenkins --> Manage Jenkins --> Plugins --> Avaiable PLugins -- Search = ssh (Public Over SSH) -> Insatll
--> Go to Dashboard of Jenkins --> Manage Jenkins --> System --> srcoll down to bottom, Click on ADD in SSH Servers, Name=Nginx-Webser, Hostanme=PublicIP og Nginx,
    username = ec2-user, Remote Directory To where Deployment path = /var/share/nginx/html
--> In Public Over SSH paste key of Nginx-Webser.pem using notepad in Key Section
---> Apply --> Save

# CASE 1
--> Go to Your Project --> Configure --> Build Enivronment --> Select = Send files or execute commands over SSH after the build runs
   --> Transfer --> Source files = **/*
--> Apply --> Save
---> Project --> Build Now  --> Console Output # To see errors any if comes

# Now give file permission to avoid error in Nginx-Webser
chmod 777 /var/share/nginx/html
chmod 777 /var/share/nginx

--> Now again Build Now

# CASE 2 - Automate Webhook Trigger
--> Go the Github --> Specific Repo --> Settings --> Webhooks --> Add Webhook --> Payload URL = http://IP:8080/github-webhook/ (Jenkins URL) --> Active & Add Webhook
--> Go to Jenkins --> Project --> Configure --> Build Triggers = Select = GitHub hok tigger fot GITscm polling --> Apply & Save
--> Now change TITLE in Github html file and save commit changes.
---> Then Refersh Website Page 2-3 times, You can the changes Automatically Done.
=====================================================================================================================================================================

=====================================================================================================================================================================
4. 27-10-24

# Install Git Bash
Open Website --> Windows --> 64-bit
git --version
--> Create new folder in that open CMD.
git clone https://github.com/codewithsadee/anon-ecommerce-website.git #Clone the repo
powershell # To download for runs like Linux Commands
cd Econ-Web-Ani
git remote -v # To check Origin Of Repo

# Open GitHub 
Create a new Repository
Go to + sign --> New Repository --> Repo Name = Multi-BMSs --> Public --> Create Repository
Copy Git Repo Link From Multi-BMSs
Then Open Cmd inside that Project Folder and paste the link
git remote set-url origin Link  # To create Alias OR Shortcut of Repo, Origin is just a name youcan give anything.
git remote -v  # To remove existing owner to You

# Now creating Branches through commands
git checkout -b Uat # Creating branch and switch also
git push origin Uat # To push from origin to Uat OR instead of origin you can use Http-Link
> Give Credentails for that and login then Authorize

# If this not working Go to Setting --> Developer Settings --> Password access tokens --> Select = Classic --> Generate new token (Classic). --> Give PW --> Note = For Git --> Selcet scopes = repo --> Generate Token. PW is equal to 12-digit Token for using credentails

git checkout -b Dev
git push origin Dev

git checkout -b Prod
git push origin Prod
 

# Now Creating Three new instance for Uat, Dev & Prod
Amazon Linux 2 AMI (HVM) --> t2.micro --> Key-pair select existing --> Allow HTTP --> Number of Instances = 3. Then change names to deticated servers.
Connect then Install Nginx in all servers.


# Now Login to Jenkins Server
# Manage Jenkins --> Plugins --> install ssh and git

# CD Now Add this Machine 
Manage Jenkins --> System --> In bottom SSH Add this machine  Name = dev-server, Hostname = Public IP, Username = ec2-user, Remote Directory = /usr/share/nginx/html
- Then Add Key = Paste Key-pair # To Authentication, OR Go to Advanced option for differnts Key-pair then paste in Use Password Key. --> Apply & Save
- Add like this for others also

=====================================================================================================================================================================

=====================================================================================================================================================================
5. 10-11-24

cd /root
cd .ssh/
ls
cat id_rsa.pub >> authorized_keys 
cat id_rsa

- Build CI-CD and integrate All servers in Jenkins.

#In Nginx Server remove pages in all three servers
rm -rf /usr/share/nginx/html/*

Should be install GIT in Jenkins servers also
yum install git -y

# In Jenkins Server
Manage Jenkins --> System --> Go to Bottom SSH Server Add servers - Name etc. Then verify with Test configuration.

# Now Creating Projets
Dashboard --> New Item --> Name = Multi-BMSs --> Select Type = Pipeline --> Ok
General  --> Select GitHub project = Give Project URL from Search Box in Reps.
Advanced Project Options --> Select Pipeline Script (Groove Script Language) Check the Use Box in that changes the Your Repos URL and Configure names and Branch Name --> Apply & Save

Manage Jenkins --> Credentails --> Global --> Add credentails --> Username of GIT & PW also OR use key, ID = Git-Pat (As mentioned in Groove Srcipt) --> Create
Give permission
chmod 777 /usr/share/nginx/html # In all Three Servers

# Now Build
Project --> Build Now

# Case 2 for Dev
Now changes in Title and Push to Dev Branch
Changes in the index.html then open Cmd inside that folder
# git checkout -b Dev OR git checkout Dev
git add .
git remote -v
git commit -m "Aniket Modified Dev-Branch-IndexFile"
git push origin Dev

Then again Run new Build Now # Check browser to see changes in all

# Case 3 for Uat
git checkout Uat
git merge Dev
Then Again Build Now

=====================================================================================================================================================================
6. 24-11-24 DevOps-git
7. 1-12-14  
=====================================================================================================================================================================
# 30th Nov Sat NEW 

Create folder in that create index.html   /opt/pharmaproject
..
create bluestyle.css
..
git init # To record all versions and history of edited
=====================================================================================================================================================================


=====================================================================================================================================================================
# 1st Dec Sun
In devloper Machine
yum insatll git -y
cd /opt/pharmaproject
touch index.html bluestyle.css  --> In working Directory
git init 
ls -a
cd .git
ls
git status  --> To check statging status
git add index.html
git status
#git rm --cached index.html  --> To remove from statging
git add -A OR git add .   --> To add ALL files

git commit -m "This is first commit rev-1"   --> -m for message
# git status --> Now it not showing because its commited.
git show  --> To see commits

git config --global user.name aniket
git config --global user.email aniket@gmail.com
cat /root/.gitconfig   --> Save in this path or U can set here directlty
git show

##rm -rf *
git checkout .   --> To get files from Local to Working directory

# Versioning Control
vi bluestyle.css --> Change color or somethinh and save
touch xyz
git add .
git status
git commit -m "This is 2nd commit rev-2"
git show

# To see all list of commits
cd .git/logs/
ls
cat HEAD

# Now push to 2.Nginx Server
insatll git in 2nd server  # firstly need to be keyless password between servers
cd /home/
git clone IP:/opt/pharmaproject
git clone user-name@IP:/opt/pharmaproject
-yes
cd /opt/
mv pharmaproject /var/www/html/
cd /var/www/html/
systemctl restart httpd


# Git Commands
git conf
git remote, add, push, commit, pull, fetch, rm, diff, show, status, show, checkout
git help  --> For subcommands
git config --help  --> For Flags

git add --> To add in Staging Area
git commit  --> To add in Local Repository

#Git Commit Has 2 Phases
1. Add to staging area from working directory
2. Taking Snapshot from Staging area to local repository

=====================================================================================================================================================================


=====================================================================================================================================================================
# 7th Dec Sat
#1 Webserver
yum update
insatll nginx  --> Its for Ubuntu OS
ls /etc/nginx/nginx.conf  --> Parent Configure
cat /etc/nginx/site-enabled/default   --> Child Configure

#Create simlink 
mkdir /etc/nginx/sites-avaiable
touch funny.com  --Symlink
ln -s /etc/nginx/sites-avaiable/funny.com /etc/nginx/site-enabled/funny.com
#unlink  --> Nginx Tutorial  https://www.ralfebert.com/tutorials/nginx-static-website-with-https/


#2 Launch new ec-2 for developer
yum update
yum install git -y
cd /opt/
mkdir pharmaprj
cd pharmaprj/
#git init --bare   --> Only For Push & Pull, Not work for editing.
git init
touch index.html bluestyle.css
git add .
git status
#git commit --> Bydefault open NANO Editer
git commit -m "This is my first commit"

Open GitHub and create new Repo name: Pharmaprj

git branch -M main
git status
git remote add origin <Repo_URL.git>
#git remote remove origin <Repo_URL.git>
cat .git/config
git remote -v /-V
git push -u origin main
-Username : GIT username
-Password : Paste Token
# In GitHub go setting - Developer Setting - Personal access token - Token (classic) - Generate token and select Repo then ADD/UPDATE, copy TOKEN
echo $? --> To check if perivous command is scuccess or not, 0-means success.

# Go to 1 Webserver
git clone <Repo_URL.git>
cp -rvp /var/www/html/
Search IP 
=====================================================================================================================================================================

=====================================================================================================================================================================
# 8th Dec Sun
AWS - IAM Therory
=====================================================================================================================================================================

=====================================================================================================================================================================
# 11th Dec Wed - Programming Notes
Basic Git Knowledge
=====================================================================================================================================================================

=====================================================================================================================================================================
# 12th Dec Thu - Git Notes
Git
=====================================================================================================================================================================

# 13th Dec Fri - Git Notes
Git  Branching
=====================================================================================================================================================================

=====================================================================================================================================================================
# 14th Dec SAT-
Java Backend Devployment

apt install nginx in Ubuntu
cd /var/www/html/
git clone httpsrepo.git
cd project;ls
start nginx, port should be open firewall80 and check in browser http:IP/project/index.html

# Task
change in code direct github html
git pull --> In server
then again see in browser and Refersh

Nginx is Static webserver
JBOSS & TOMCAT is Dyanmic webserver for JAVA 

Download eclipse and Install IDE- Integrated Devployment Enivronment
Object, Classes, Connector

=====================================================================================================================================================================

=====================================================================================================================================================================
# 18th Dec Wed - Git Notes
Git - PR, MR, FORK, Reset & Revert.
=====================================================================================================================================================================

=====================================================================================================================================================================
# 19th Dec Thu - Git Notes
Git - Stash, Reflog & CheeryPick
=====================================================================================================================================================================

=====================================================================================================================================================================
# 20th Dec Fri  - Git Notes 6
Git - Rebase  & DOCKER
=====================================================================================================================================================================

=====================================================================================================================================================================
# 21th Dec SAT-  MAVEN

### Project Maven ###

Maven Phase - 
Validate
Compile
TEST - Unit Test
BUILD
PACKAGE, INTEGRATION, INSTALL
DEPLOY - As a WAR

#1. Launch One Ubuntu instance for Maven
sudo -i
apt update 
apt install maven
dpkg -l | grep -i maven

mvn

mkdir /opt/javproject
cd /opt/javproject
# mvn archetype:generate -DgroupID=com.example -DartifcatID=DemoApp - DarchetypeArtifactID=maven=archetype-webapp -DinteractiveMode=false 
mvn archetype:generate -DgroupID=com.example -DartifcatID=javaapp - DarchetypeArtifactID=maven=archetype-webapp -DinteractiveMode=false 
echo $?
stty -ctlecho
ls
apt install tree
tree 
cd javaapp/ ; ls
cat src/main/webapp/index.js
cat /opt/javproject/javaapp/pom.xml

pom.xml --> Project Object Model is a refernce file for the maven and IT IS HEART OF MAVEN.
Or POM is the fundamental, It is an XML file contains information about the project and configuration details used by Maven to build the project.

# Creating WAR file and give to TOMCAT
cd /opt/javproject/javaapp/  --> For creating war always inside the App
ls  --> O/P shows po.xml
tree
#mvn clean  --> To remove created Build
#mvn clean package --> first remove then create new Build at one command.

mvn package  --> Creating Build
ls : tree
mvn clean

mkdir -p src/main/java/com/example
cd src/main/java/com/example/

vi HelloServlet.java
Paste code and save

cd /opt/javproject/javaapp/
tree
mvn package  # Fail beacuse of version

vi pom.xml
paste and save 

mvn package ; tree

#2. Launch Ubuntu new instance for TOMCAT server
version 9 & 10 in Tomcat

download rpm or tar.gz
cd /opt/
wget .....tar.gz
echo $? ; ls
tar -zxvf apc...tar.gz
ls
cd tomcat
ls
apt update
#apt search jdk
apt-get  install default-jdk -y
java -version

/opt/tomcat10/bin/startup.sh run   # Start Tomcat & run on port 8080, Requires Java, open port also 
/opt/tomcat10/bin/shutdown.sh run  --> To Stop
ss -ant | grep -i 8080

search IP:8080 in browser

# cd /opt/tomcat10/webapps/
Paste the javaapp.war file in that location
http://IP:8080/javaapp
=====================================================================================================================================================================

=====================================================================================================================================================================
# 22th Dec SUN-
 Maven + Tomcat
 
1. Maven definations 
2. TOMCAT - WAR Deployment
3. TOMCAT - manager deploy (multiple branches)
4. NGINX - REVERSE PROXY TO TOMCAT - Prod
5. ANSIBLE 

Maven is a build automation tool primarly used for java projects, Main two main aspects of building software
1. Project build lifecycle managemnet. 2. Dependency management.

Only for JAVA 

Plugins - use goals 
Heart - all work is done by plugins. Looking for a specific goal to execute.

Maven - POM.xml
Dependencies - List all the external libraries your project depends on. Maven will download these libraries automatically from the central repository.
Three Repository :
Local,   Central,   Remote Repository 
Local - Local folder structure.
Central - Repos over the internet.
Remote Repository - Repos over the internet.

# When we create Artifact (JavaApp), we not send in Git instead of send Artifact Repository and versioning also. Software like jfrog and nexus etc.

# What is Artifactory 
For hosting and managing, and distributing binaries and artifacts. Any type of software in binary form - such as application installers, container images etc.


# Now in Tomcat Server.
Install Tomcat and configure 
sudo -i
sudo apt-get install default jdk -y 
sudo useradd -m -U -d /opt/tomcat -s /bin/false tomcat
sudo wget download from link browser and paste here in /opt.
sudo tar -xzvf apache-tomcat-10.0.20.tar.gz
Rename the folder to short name.
sudo mv apache-tomcat-10.0.20.tar.gz /opt/tomcat/tomcat
sudo chown -R tomcat:tomcat /opt/tomcat/tomcat


Tomcat is a Dynamic server 
Tomcat is a Java Servlet Container 
Tomcat can run JVMS.
Tomcat Port : 8080
Tomcat to start requires - Java and Java_home path

What is Servlet?
It is a type of Program which is deployed in Java - Java Servlet.

whereis java
find / -iname java

When you install package from using tar, it's  install in a single folder and create all folders like /bin /etc.
In other when you install package from using yum/apt-get it's install in all folders like /bin /etc.

# There are three types of commands to start Tomcat 
1. /opt/tomcat/tomcat/bin/catalina.sh run #Run with logs and Debug mode.
2. /opt/tomcat/tomcat/bin/startup.sh run #Background starts
3. systemctl start tomcat #But required unit service files.

# To stop
/opt/tomcat/tomcat/bin/shutdown.sh run

IP:8080 #To see webpage in browser and open port.

# Three are main folders in Tomcat.
1. bin
    - Binaries and start service files.
2. config  
    - server.xml file.
3. webapps
     -  webapplication host war.app file.
     -  ROOT
          - index.jsp


# Now from Devloper machine Maven, push war file in Git. Or Take sample project from Net like sample Hello world project using wget command.
Then Pull war file in Tomcat server and move to webapps folder.
- When you provide war in webapps folder, it's automatically untar and start the Artifact.

# jar -tf file.war  --> To see content of war file # Search exact command in NET.


# Now Reverse Proxy 
In same machine of Tomcat 
Install Nginx.
cd /
apt install nginx -y
systemctl restart nginx and check status/enable 
vim /etc/nginx/conf.d/tomcat.conf  --> create this file and paste
proxy......... And your instance IP.
In last give redirect IPandPort, it's means Tomcat webpage link http..../;

Then restart nginx service.
Then search in browser 
https//IP only
http://IP/ad1-projetname/
=====================================================================================================================================================================

=====================================================================================================================================================================
# 24th Dec Tue  - DOCKER 2
Docker Images
=====================================================================================================================================================================

=====================================================================================================================================================================
# 25th Dec Wed Docker -3
PORT MAPPING
=====================================================================================================================================================================

=====================================================================================================================================================================
# 26th Dec Thu Docker - 4
Docker Containers, Data Migration
=====================================================================================================================================================================

=====================================================================================================================================================================
# 28th Dec SAT- Tomcat Deploy

POC - Prove of Concept, Build and Test, Dummy Replica
TSD - Technical Solution Document

# POC-PROOF OF CONCEPT

A proof of concept, or POC, is an experiment intended to show that a program, product, or system can be successfully deployed in the real world
demo project that reflects a real-world scenario.

DEMO SERVER-- A demo is a quick illustration for potential clients (ARCHITECTURE)
A proof of concept helps prove that a system can work effectively in the market itsel

LOAD-STRESS TESTING

# POC --- same as prod process will be done

1. development code
2. GIT --- repso - GIT push code = GIT hub
3. Frontend + application code ---- direct nginx/apache host
4. Bacekend -- Java + maven or ant or gradle build---- junit test +  code scan (sonarcube) + tomcat deploy -to nginx redirect


Get war file via using Git or SCP in webapps folder not ROOT Folder.

jar -tf sample.war
Install Tomcat and untar the war file

The start the file via using shartup command.

ps -el | grep -i java
ss -tulnp | grep -i <PID>
lsof -i :8080

---- webapps/ROOT/
Here index.js  --> Available 
Search IP and webapps path --> To see Page

Set-up systemctl service.

1. Uncomment the user details section and change the password for user & robot also : vi opt/tomcat/tomcat/config/tomcat-users.xml

2. Paste the code : vi opt/tomcat/tomcat/webapps/manager/META-INF/context.xml

3. Then restart the service 

/startup.sh

Tomcat port -security groupport opn 8080

WE DEPLOYED A WEB APPLICATION (javapplication WAR) --15 WEBAPPLICATION WAR-DEPLOY -


TOMCAT VERSIOn 9 and TOMCAT 10

get the application from any source git winscp s3

copy to webapp

HOW TO DEPLOY WEBAPP WAR FILES WITH TOMCAT WEBGUI
- Using Web Application.


ant
maven
gradle

INTERVIEW QS

ant vs maven gradle
maven-xml --
gradle grrovy script
gradle advanced
=====================================================================================================================================================================


=====================================================================================================================================================================
# 29th Dec SUN- Git Branching & Basic HTML

In first half, how to pull specific branch code.
git push -u origin uat

git clone --single-branch --branch dev https.//.git   # To Pull specific branch content only, so URL is same only add branch tag and name.

## In second half Basic tags of HTML.
<br/> <h1>.. etc
=====================================================================================================================================================================


=====================================================================================================================================================================
# 03th Jan Fri Docker - 5
Docker State
=====================================================================================================================================================================


=====================================================================================================================================================================
# 04th JAN SAT- Ansible Therory

- Pipeline and Stages Therory and Visualation.

cd tomcat/webapps
ls ; javaapp.war

# Configuration Management Tool - For easy shell Ansible scripting.

## Ansible Insatllation and Therory
Should be password less servers.

vi /etc/ansible/hosts    # To add groups of IPs.
 [webserves]
 1.2.3.4
 1.2.3.5
 [mailservers]
 1.2.3.6
 1.2.3.7

# Cmds
ansible all -a uptime
ansible webserver -a "uname -a"   ## For Webservers IPs.
ansible all -m user -a "name=john password=redhat"

See screenshot C:\Users\Dell\Desktop\IPM_CMDS\SS\SS_1.png

=====================================================================================================================================================================


=====================================================================================================================================================================
# 05th JAN SUN- ANSIBLE

ansible all -m ping    # To check ping with others servers.
ansible all -m user -a "name=ramu state=present"     # To check user is present or not, If not they created. If already exists then show
ansible all -m user -a " name=ramu state=absent"    # To delete the user.

rpm -qa httpd   # To check.
rpm -qi.   # Shows when installed Date & Time.

ansible all -m yum -a "name=httpd state=present"    # To install httpd.
ansible-doc -l     # To show all modules in ansibile. 
ansible-doc git   # To show manual of git.
---   # Triple dash use for multiple playbook task in one playbook file.
...   # To end playbook if using multiple plays in one file.


### ANSIBLE ARCHITECTURE

1vm -- master node --- multiple clinets / hosts
ansible Push based
ansible agentless
ansible uses python

1. Prerequsite --- ssh passwordless between master and nodes
2. master ansible install
3. Root PAth --- /etc/ansible/ # ALL ansible files
4. Ansible main PRG -- /usr/bin/ansible --- > prg - -main command
5. /etc/ansible/ansible.cfg --- > ansible config file
6. /etc/ansible/host --- > ansible inventory file (hosts ips mention)
7. ansible has many modules -- every comand is used as a module
8. Ansible check how many modules ---- ansible-doc -l

Ansible Module 1600-1700 modules are more than avaiable till now.

# Comparison Ansible vs Puppet vs Chef #

## ANSIBLE  ##              
Agentless               
Push Model
Playbook
Tasks
Ansible Control M
Hosts
Python, YAML
easiest install
SSH/NETCONF
declerative
system admins
easiest
2012

## PUPPET ##
Both
Pull Model
Manifest
Resources
Puppet Master
Agent
Puppet DSL, ERB
easy install
REST
declerative
system admins
intermediate
2005

## CHEF ##
Agent Based
Pull Model
Recipe
Resources
Chef Server
Clients
Ruby DSL
medium install
REST
imperative
developers
advanced
2009
---------------

ANSIBLE ---
Ansible is configuration management tool used to perfrom multiple task on multiples nodes

Use case
1. nginx config change -- sites available symlink
   systemctl nginx restart --- >25 nodes
2. git clone webapp.war clone --- >copy to /tomcat/webapps
   tomcat service staop and start
3. php package yum install
   php module add apache
4. php config --- > server --- copy to php.conf -- > apache /etc/httpd (condition -- if copied)
5. restart else do not restart


---

## XML ##
<Servers>
     <Server>
	   <name>Webserver</name>
       <os>Redhat</os>

       </Server>
</Servers>

## JSON ##
{
 Servers: {
  {
    name: webServer
    os: Redhat
	}
  }
 }

## YAML ##
Severs:
   - name: webserver
     os: Redhat
------------------------

cat /opt/pharma.yaml
- hosts: webserver
  tasks:
  - name: create a user
    user: name=john state=present
## End

ansible all -m user "name=john state=present"       # To check user is added or not, if not then create the user.
ansible-playbook /opt/pharma.yaml --syntax-check    # To check syntax in that file.


WHAT Is playbook
playbook is a collection of multiple add-hoc commands
Ansible playbook is a file that contains a set of instructions that Ansible can use to automate tasks on remote hosts.
A playbook typically consists of one or more plays, a collection of tasks run in sequence.

Playbook
| Play
   | Task
      | yum -- module(cmd)
	  | user -- module(cmd)
	  
	  
	  
ansible all -m user -a "name=john" password=redhat'

ansible all -a "yum install httpd"
ansible all -a "yum remove httpd"

ansible all -m yum -a "name=httpd state=absent"
ansible all -m yum -a "name=dovecot state=present"

ansible webservers -a 'uptime'
ansible webservers -m shell -a "service sshd status"
ansible webservers -m shell -a "service httpd status"
###########################################
ansible webservers -m command -a 'df -h'

ansible webservers -m copy -a "src=/root/xyz.txt dest=/opt/funny

ansible webservers -m copy -a "src=/home/* dest=/opt/funny

What is Playbook ---- collection of add-hoc commands
  written in YAML language --- YET Another Markup Language
XML + YAML + JSON Data Serialization language ---
used to pass data tp apps or web

abc.yaml  abc.yml  abc.py  abc.sh   abc.js
--- file begin
AWS -- IAM POLICIES -- JSON LANGUAGE - S3 policy
Docker Kubernetes ansible - yaml

=====================================================================================================================================================================


=====================================================================================================================================================================
# 05th Jan Sun Eve
=====================================================================================================================================================================



=====================================================================================================================================================================
# 08th Jan Wed - Docker DockerHUB - 6
Pull, Convert from Conatiner to Image
=====================================================================================================================================================================

=====================================================================================================================================================================
# 09th Jan Thu Docker Volume - 7
Volume, Basic Dockerfile
=====================================================================================================================================================================

=====================================================================================================================================================================
# 10th Jan Fri - Docker - DockerFile - 8
Dockerfile, CustomDockerFileName & Docker Therory
=====================================================================================================================================================================

=====================================================================================================================================================================
# 11th Jan SAT- ANSIBLE

- name: Intro to Ansible Playbooks
  hosts: all
  tasks:
  - name: Copy file hosts with permissions
    ansible.builtin.copy:
     src: ./hosts
     dest: /tmp/hosts_backup
     mode: '0644'
  - name: Add the user 'bob'
    ansible.builtin.user:
      name: bob
      become: yes
      become method: sudo
.

Ansible Playbook syntax -:
1. become
2. when
3. notify
4. handler
5. var - -variable
.

myplaybook-1.yml
#play
	 - hosts: webserver
	 - name: group and user created
	   tasks:
	   -group: name=market state=present
	   - user: name=ramu state=present
 
#play2
      - hosts: devserver
	  - name: package installation
        tasks
        - yum: name=httpd state=present
        - service: name=httpd state=start
#end

# Flow of cmds
Playbook-1
    |
  play
    |
  Tasks
    |
 module-cmds	
.

#play3
- hosts: devserver
  tasks:
  - copy:
     src: /opt/funny/index.html
	 dest: /usr/local/
.

YAML ---
objects
key
value pairs
ist
distionary
sequence
block
mappings

.

ansible-playbook -vvv /opt/myplaybook-2.yml    # playbook run
ansible-playbook /opt/myplaybook-2.yml    # playbook run

.

STEPS ANSIBLE:
5. ansibledoc-l to see all modules bcoz works on module based -- EVERY command runs as a module

6. ansibledoc <modulename> --- manual of that module/command - use that command

7. Ansible playbook - are written YAML - yetanaother markup language -Data serial language
.yml .yaml .json

8. Ansible playbook --- its a file -- collection of commands/modules --- ie - Task Definition

9. playbook check ---- ansible-playbook <file.yml> -- syntax-check
run playbook ansible-playbook <file.yml>

10. ANSIBLe - ROLES ---- ansible --- collection of playbooks
ANSIBLE ROLES
collections of files, tasks, templates, variables, and modules.
The role is used for breaking a playbook into multiple files
Roles are a way to group multiple tasks together into one container to do the automation

11. ANSIBLE - VAULT --- ansible --- use this vault -- to keep password in encrypted format
-- will share encryoted password to playbook and addhooc commands via ansible vault
Allows you to keep sensitive data such as passwords or keys in encrypted files, rather than as plaintext in playbooks or roles.
			#ansible-playbook /opt/myplaybook-3.yml -- ask-vault-pass /opt/xyz.xml

12. Ansible Galaxy --- REPOSITORY
Ansible Galaxy is website with repository, where users can share roles for installing, creating, and managing roles

13. Ansible Tower ---- - web interface graphically -- manage everything
(create playbooks + run add -h oc commands- create roles - vaults)
Ansible is a product of redhat --- ansible tower - -redhat provides support
.

## FLOW CHART
             Role-1
		|                |
   playbook1         playbook2
  |      |               |
plays plays             plays
 |     |      |          |
tasks tasks tasks       tasks
.

# To vault PW
ansible-vault create /opt/abc.yml
ansible-vault view /opt/abc.yml
vi /opt/xyz.yml

ansible-playbook /opt/myplaybook-3.yml -- ask-vault-pass /opt/xyz. xml
.

why play book
- collection
 - playbooks
  - plays
   - tasks
    - module
     - arguments
	 
ansible-playbook -i /opt/inventory /opt/playbook.com 
.

Terraform Kubernetes
YAML -- Yet another Markup Language

1. Blocks
2. Sequence
3. Map
4. Object V
5. Key value
6. list
7. dictionary
8. Indentation
.

JSON TO YAML
{
 "cricketers": [
 "dhoni",
 "sachin",
 "rohit",
 "virat"
 ]

=====================================================================================================================================================================

=====================================================================================================================================================================
# 12th Jan SUN- ANSIBLE Playbook

---
- name: centos configure
  hosts: all
  tasks:
  - name: install nginx
    yum:
    name: nginx
    state: present

- name: start nginx
  service:
   name: nginx
   state: started
.

- name: Example of defining variables on Ubuntu
hosts: all
become: yes
vars:
username: admin
max_connections: 100
tasks:
- name: Print the username
debug:
msg: "The username is {{ username }}"
.

- name: Configure max connections in sysctl.conf
lineinfile:
path: /etc/sysctl.conf
regexp: "net.core.somaxconn'
line: "net.core.somaxconn = {{ max_connections ]]"
notify:
- Reload sysctl

handlers:
- name: Reload sysctl
command: sysctl -p
.

ansible-addhoc -m yum name=http state=present
##ansible-addhoc all -m yum name=http state=present --become=yes (as root user change)
#become as a root user
##ansible-addhoc all -m yum name=http state=present --become_user=shamu (as root user change)
.

lineinfile:
path: /etc/sysctl.conf
regexp:"net.core.somaxconn'
line: "net.core.somaxconn = {{ max_connections }}"
notify:
- Reload sysctl

handlers:
- name: Reload sysctl
command: sysctl -p

become method allows you to elevate privileges for specific tasks or an entire playbook, enabling the use of sudo
.

variable
variablename=value
student=ramu shamu
dhamu

---
- hosts
  vars:
  students:
  - ramu
  - shamu
  - dhamu
  
tasks:
- name: 1000 users create
  user: "{{ students }}"
  state: present

tasks:
 - name: Print the username
   debug:
      msg: "The username is {{ students }}"
	  
handlers:
notify: Restart Nginx

## when : he task will run only if the condition is true. If it is false, the task will be skipped

## handlers : handlers are typically used to start, reload, restart, and stop services. you want a task to run only when a change is made on a machine
handlers are special tasks that only get executed when triggered via the notify directive. Handlers are executed at the end of the play, once all tasks are finishe

LINK : https://blogs.teliosautomation.com/using-variables-and-loops-in-yaml-with-ansible/

usercreatre
task:
 user: state present
 notify: usercreated
handler:
 name: usercreated
 copy:
  src: /etc/skel/.prof

---
- name: Verify apache installation
hosts: webservers
vars:
http_port: 88
max_clients: 200
remote_user: root [>
tasks:
- name: Ensure apache is at the latest version
ansible.builtin.yum:
name: httpd
state: latest

- name: Write the apache config file
ansible.builtin.template:
src: /srv/httpd.j2
dest: /etc/httpd.conf
notify:
- Restart apathe

- name: Ensure apache is running
ansible.builtin.service:
name: httpd
state: started

handlers:
- name: Restart apache
ansible.builtin.service:
name: httpd
state: restarted
.

## Create a template and use various files.

cd /opt/
mkdir roles
ls all.yml
ls roles/
cd roles/


mkdir -p mailserver/tasks ; cd mailserver/tasks/ --- > touch

mkdir webserver/tasks --- > touch main.yml
mkdir dbserver /tasks --- > touch main.yml

touch /opt/roles/mailserver/tasks/main.yml
- name add ssh keys
tags: alsways
authorized_keys:
user: simone
Key: ssh

touch /opt/roles/webserver/tasks/mainyml

- name: install apache
tags: apache
apt:
name:
 - apache
 - libapache-php
state: latest

# Creating playbok using template to segerated.
 playbook =-- allyml -- cp allyml before-roles.yml
ansible-playbook all.yml

hosts: mailserver
 become: true
 roles:
 - maileerver
.

# To use yaml extenions like we use in VScode. This is not exact correct serach.
vim .vimrc 
autocmd FileType yaml setlocal ai ts=2 sw=2 et cursorcolumn
 
HISTORY
mkdir /opt/roles
cd roles/
mkdir -p webserver/tasks
mkdir -p mailserver/tasks
mkdir -p dbserver/tasks
touch webserver/tasks/main.yml
touch mailserver/tasks/main.yml
touch webserver/tasks/main.yml

=====================================================================================================================================================================

=====================================================================================================================================================================
# 16th Jan Thu - Docker - DockerFile - 9
Dockerfile, FROM, ENV, LABEL, COPY, WORKDIR
=====================================================================================================================================================================

=====================================================================================================================================================================
# 17th Jan Fri - Docker - DockerFile - 10
Dockerfile, ADD, CMD
=====================================================================================================================================================================

================================================================================================================================================================
# 18th JAN SAT- Ansible Playbook

- name
yum

Playbook
host: webserver
- name service
  service

- name
  handler

host: mailserver
- name
  copy
  src

- name
  when

hosts: dbserver
- name
  git: git clone
.
  
var/main.yml
we can create a role structure hierarchy
ansible-galaxy init db

| rolename - db
    defaults
      | main.yml
    files
    handlers
       main.yml
    tasks
       main.yml
    meta
       main.yml
	vars
       | main.yml
.

WHAT IS CI
Continous Integration = Continous BuilD
Build ---- list of prgs/tools run in sequence with the help of plugins

Continuos Integration Server Brand -:
Cl Server / Build Server / Integration Server / Plugins use
1. Jenkins -- one the leader
2. Gircle Ci
3. teamcity
4. bamboo
5. gitlab CI
6. github actions
.

# CI TOOLS-
1. Jenkins
2. Circle C
3. teamcity
4. bamboo
5. gitlab C
6. github actions

CI SERVEr Plugin list
1. git
2. git hub plugin
3. nginx plugin
4. docker plugin
5. ssh plugin
6. maven plugin
etc -- 1000s of plugin --
================================================================================================================================================================

=====================================================================================================================================================================
# 19th Jan SUN - Jenkins

git fetch  # Means take small change and pull means take full code. 

In Ubuntu 
dpkg -l | grep -i jenkins 
dpkg -L jenkins  # Its show all jenkins files
ps -ef | grep -i java 
systemctl status jenkins 
tree -f  # To see exactl path

/var/lib/jenkins  # Main path. 
/usr/bin/jenkins  # Main Binary path. 
/var/lib/jenkins/config.xml   # Main Global Jenkins configuration file. 
/var/lib/jenkins/workspace  # Default path of workspace. 
/var/lib/jenkins/jobs  # Jobs path. 
/var/lib/jenkins/plugins  # Plugins path and save as plugins_name.xml.jpi
/var/lib/jenkins/secrets  # credentials and migration one server to another server. 


Workspace - working directory for versioning control. 
jobs > myjob1 > --config.xml   # For particular job config file. 
jobs > build > build.xml and log


## Job-1
New item -job-1 echo - freestyle project - ok
Build - Add build steps - select Execute shell
 echo who r u
  mkdir abc   # its create in /var/lib/jenkins/workspace/job-1/abc.
Save. 

= Build Now

# To check in server
tree -f -n 1 /var/lib/jenkins/ | grep -i job1

/var/lib/jenkins/
	|-- config.xml
	|
Workspace -- working directory for versioning control
	| - pharmaproject # git code

Jobs
	|
	 mynginx-job-1
		  | -- config.xml
		  | -builds
 		     =| Build_id -1
					   | -- build.xml
					   | - log # console log
| mykubernetes-job
		| - config.xml
		| - builds
			  | Build_id-1
					| build.xml
					| log
				|Buil_id-2
				|build.xml
				 |log

=====================================================================================================================================================================

=====================================================================================================================================================================
# 19th Jan Sun Eve
=====================================================================================================================================================================


=====================================================================================================================================================================
# 21th Jan Tue - Docker - Pending - 11 -----------
=====================================================================================================================================================================


=====================================================================================================================================================================
# 22th Jan Wed - Docker - Pending - 12 -----------
=====================================================================================================================================================================


=====================================================================================================================================================================
# 23th Jan Thu - Mini-Project-1_Jenkins_1
# Requirements: Developer, GitHub, Jenkins server-1, Ansible-server-1, Web-server-1 Nginx.
=====================================================================================================================================================================


=====================================================================================================================================================================
# 24th Jan Fri - Mini-Project-1_Jenkins_2
# Requirements: Developer, GitHub, Jenkins server-1, Ansible-server-1, Web-server-1 Nginx.
=====================================================================================================================================================================


=====================================================================================================================================================================
# 25th JAN SAT- Jenkins

systemctl ststus jenkins -l # To see background process. 
ps -ef | grep -i java # To see jetty process which is use by java. 
ps - el | grep -i java # Doesn't not show ps process only show which running process we search. 
strace systemctl start jenkins # To see all background process while starting service. 
lsof -i :8080 # To see port. 

Webhook also required port open for sometimes because of security reasons.

-JENKINS
default USER
jenkins - backend process

admin user - ramu
jenkins portal all rights
instruction to jenkins
(build install plugin)

ramu --
normal user -- shamu
(jenkins portal limited rights)
(only build -- not install plugin)
.

#TASK --
1. developer will plan and write code
2. Push code to Git hub
3. Github -- store the code - remote repos
4. Github --- > will send the code to jenkins
5. Jenkins will clone/pull/fetch the code from Github and store in Workspace

# ARCHITECTURE Diagram of Jenkins
Path ="C:\Users\Dell\Desktop\IPM_CMDS\SS\SS_6__25-1-25.png"

# TASK-1 [ CI ]
New item = job1 --> Freestyle --> 
SCM --> Git --> Repo URL = paste link 
Save --> Build.

=====================================================================================================================================================================


=====================================================================================================================================================================
# 26th JAN SUN- Jenkins

# TASK-2 [ CD ]
Build Triggrs
Job --> Configuration --> Build Triggers

In SCM
1. Build Periodically - It fetch and run new build that particular time complusary (00 18 * * *).
2. Poll SCM - It ask to git, if new commits are there or not, if new commit present then pull the code (/18) Or use like crontab lines.
   - It works similar to webhook but opposite means in this case github is triggering the job and jenkins will check for commits.
   - Now we will select pol scm option in jenkins job build trigger option and define time whenever it runs:

## scp -rv * 192.168.0.10:/var/ww/html/  # To copy from jenkins to nginx server, for maually or In Build step --> Excute shell.
chmod o+w /usr/share/nginx/html/  # Its required or give error while build

# Download PublicOverSSH plugin
--> Manage --> configure --> PublicOverSSH  # In Global configuration.
 paste key. --> Give Name= Nginx Web-server, Hostname= IP, Username= root/ec2-user, Remote Directory= /var/ww/html/
--> Job --> Configuration --> Build Triggers --> GitHub hook trigger for GITsm polling.
    --> Build Enivronment --> Send files or execute commands over SSH after the build runs.
        Name=select Nginx, Transfer Set= **/*, or give exact-path, Remote directory= Already give in main configuration Or now U can give.
Save --> Build.

# TASK-3
--> Job --> Pipeline

#Pipeline Script:
pipeline {
    agent any
    environment {
	    TOMCAT_PATH = "/opt/tomcat"
        TOMCAT_USER = "root"
        TOMCAT_PASSWORD = "admin"
        TOMCAT_IP = "172.31.38.87"
	}
	stages {
       stage('Checkout') {
          steps {
              git branch: 'main', url: 'https://github.com/Azure-Samples/tomcat10-jakartaee9.git'
            }
		}
	}
    stage('Build') {	
	    steps {
	        script {
			    sh 'mvn clean install'
            }
		}
	}
    stage('Deploy to Tomcat') {
        steps {
            script {
                def warFile = 'target/ *. war'
                def remoteWarPath = "${TOMCAT_PATH}/webapps"
                
                // Debug the variables
                echo "WAR file path: ${warFile}"
                echo "Remote path: ${remoteWarPath}"
                echo "Tomcat user: ${TOMCAT_USER}"
                echo "Tomcat IP: ${TOMCAT_IP}"
                
                // Use sshpass with SCP to copy the WAR file to the remote Tomcat server
                sh "sshpass -p '${TOMCAT_PASSWORD]' scp -v -o StrictHostKeyChecking=no ${warFile)${TOMCAT_USER)@${TOMCAT_IP]:${remoteWarPath]"

	            // Restart Tomcat by SSHing into the server
                sh "sshpass -p '${TOMCAT_PASSWORD}' ssh -v -o StrictHostKeyChecking=no ${TOMCAT_USER]@${TOMCAT_IP}'${TOMCAT_PATH}/bin/shutdown.sh &&
				
${TOMCAT_PATH}/bin/startup.sh'"		
                }
    		}
    	}

        post {
            success {
                echo 'Build and Deployment Successful'
            }
            failure {
                echo 'Build or Deployment Failed'
            }
		}
	}		
=====================================================================================================================================================================


=====================================================================================================================================================================
# 26th Jan sun Eve Js
=====================================================================================================================================================================


=====================================================================================================================================================================
# 27th Jan Mon - Mini-Project-1_Jenkins_3
# Requirements: Developer, GitHub, Jenkins server-1, Ansible-server-1, Web-server-1 Nginx.
=====================================================================================================================================================================


=====================================================================================================================================================================
# 29th Jan Wed - Mini-Project-1_Jenkins_4
# Requirements: Developer, GitHub, Jenkins server-1, Ansible-server-1,Docker, Web-server-1 Nginx.
=====================================================================================================================================================================


=====================================================================================================================================================================
# 31th Jan Fri - Mini-Project-1_Jenkins_5
# Requirements: Developer, GitHub, Jenkins server-1, Ansible-server-1,Docker, Web-server-1 Nginx.
=====================================================================================================================================================================




----------------------------------------------------------------------------------
## 01 FEB SAT- JENKINS ##
First Half Hour 10:05AM to 10:25AM
SDLC - Software Development Life Cycle

## Remaining  ##
Part is below

DEVOPS MEANS AUTOMATION OF SDLC ------
THIS REQUIRED multiple tools --- VISUAL CODE + GIT + GITHUB + Maven + Junit test + Sonarcube + (Nexus + JFROC artifacts repos) + ANSIBLE + DOCKER + KUBERNETES + Promethus + Graffana)

https://medium.com/django-unleashed/technical-guide-end-to-end-ci-cd-devops-with-jenkins-docker-kubernetes-argocd-github-actions-fee466fe949e
https://medium.com/@vinoji2005/day-18-gitlab-ci-cd-for-serverless-deployments-dc23a51d9cd5
https://ghumare64.medium.com/devops-roadmap-2025-352da3d08251
https://medium.com/@sayalishewale12/complete-jenkins-ci-cd-project-a2144b0blcd2https://medium.com/@kulkarnidhananjay89/part-2-building-jobs-with-jenkins-declarative-pipeline-4feb11104d4c
https://sourabhkalalmedium.com/day27-advanced-jenkins-pipelines-and-automation-875544956f65

#Example of junit in jenkins shell
- jobs - Build steps - Excute shell --> 
junit /target src --- coe 
echo "This is a test"

# New Task #  (How to run multiple jobs one after another)
Create three new jobs.
# It means when A is build and stable then automatically B also is build.
A-jobtest-1, B-jobtest-2 & C-jobtest-3

# In A-jobtest-1.
Excute shell -> Build other projects
Name = B-jobtest-2
Select first option = Trigger only if build is stable.
Save.

# In B-jobtest-2.
Excute shell -> Build other projects
Name = C-jobtest-3
Select first option = Trigger only if build is stable.
Save.

# In Dashboard #
To see Graphically building new jobs.
Click on New View
Plugins: Download Delivery Pipeline Plugin 1.4.2
- Jobs -> Edid View --> Pipeline
   Name & Job --> Update interval: select: 1 Enable start of new pipeline build, 3 Enable rebuild.

# Pipeline has two types #
1. Scripted - old   2. Declarative - New

Jenkins pipelines are traditionally written as scripted pipelines. Ideally, the scripted
pipeline is stored in Jenkins webUI as a Jenkins file. The end-to-end scripted pipeline
script is written in Groovy.

The Declarative Pipeline subsystem in Jenkins Pipeline is relatively new, and provides
a simplified, opinionated syntax on top of the Pipeline subsystems.

pipeline {        ## // It means Declarative
    agent any
    stages {
        stage('Welcome Step') {
            steps {
                echo 'Welcome to LambdaTest'
            }
        }
    }
}

Link: https//dba12c.wordpress.com/2022/06/10/jenkins-declarative-pipeline-tutorial


node {            ## // It means Scripted
	stage('Build') {
	
	}
	stage('Test') {
	
	}
	stage('Deploy') {
	
	}
}

#In Linux Shell
hello() { echo let us be a frd ; }
(baçkup) { rsync -avz /opt/* /mnt }


# Write pipeline as declarative start
pipeline {
    stages {
        stage1 ('git clone') {     // Give Unique Name to Understand
            steps {
			git clone ...
			}
		}
	    stage1 ('deploymentnginx') {
            steps {
               sh scp -rv
			   }
        } 			   


Second 12:53AM to 1:20AM 
In Jenkins pipeline - Only stage allowed not stages1 ..2..3
Run the script and check with Vscode.
Block, Parentheses() called also function, Curly bracket - Expansion Bracket{} called aslo set of instructions.
Stages
--------------------
=====================================================================================================================================================================

=====================================================================================================================================================================
# 02 Feb SUN - Jenkins
Full Video Problem.

cook() {echo this is chef; }. # In Linux 
environment is used to set variables 
_----------------ss_____

=====================================================================================================================================================================


=====================================================================================================================================================================
# 08 Feb SAT - Jenkins

# Means jenkins script getting from Git and then build a new job.
-JOBS - Pipeline Style
Pipeline = Pipeline script from SCM
#VITAL#
Branch name = */main
Script Path = jenkinsfile

# In Git Repo
pipeline {
    agent any
    stages ('build'){
        stage {
            steps {
                echo 'This is Build'
            }
        }
    }
}


# DECLARATIVE (GROOVY) and SCRIPTED (GROOVY) -- DIFFERENCE BETWEEN #

# DECLARATIVE (GROOVY)
pipeline
Build
restart /rebuild
specific stage rebuild
lengthy pipeline
Declarative pipeline - Groovy-based DSL (Domain-Specific Language)

# SCRIPTED (GROOVY)
node
Build
restart all stage will be restarted
solowness
more functions operators are used in scripted
complex pipeline -- less lines.
Scripted -Scripted Pipeline is the original pipeline syntax for Jenkins


PIPELINE - ELEMENTS
1. BLOCK
2. Directives
3. functions
4. Arrays
5. if else condition
6. Condition
7. Paramterized
8. Post


1. BLOCK
pipeline
stages
steps
stage
script

2. Directives -- are also called section
environment
option
triggers



### PIPELINE SYNTAX ###
https://www.jenkins.io/doc/book/pipeline/syntax/
https://www.baeldung.com/ops/jenkins-conditional-constructs#:~: text=Effective%20Jenkins%20pipelines%20rely%20heavily,steps%2C%20or%20any%20other%20condition
https://www.lambdatest.com/blog/jenkins-declarative-pipeline-examples/
https://www.lambdatest.com/blog/what-is-jenkins/

# Environemtn variable
https://phoenixnap.com/kb/jenkins-environment-variables


a=b  --> Varaiable Value
a==b --> Comparison


## HOW TO SET CREDENTIALS IN JENKINS Security
CRDENTIALS method
- username and password
- secret file
- secret text
- ssh private key


# Temlate
In Dashboard --> Mange jenkins --> Credentails
- Add credentails
Scope = Global (Jenkins, nodes, items, all child items, etc)
Username = ubuntu
Password = x
ID = nginx_login   # Give unique name to use in script, else jenkins give very long number names.
Description = This is nginx description servers details.


HOW TO SET CREDENTIALS IN JENKINS :
pipeline {
    agent any
 environment {           # It means use for globally, can use any stages.
   salman_cred=credentials('nginx_login')
}
stages {
  stage('CALLCRED') {
    environment {        # It means use for stage only for globally or other stages.
	
	}
   steps {
    echo "Username is $salman_cred"
    echo "Password is $salman_cred"
}
}
}
}


# New Credentails #
Kind = Secret file
Scope = Global (Jenkins, nodes, items, all child items, etc)
choose file : create new file or use sceret Private key.

## New 
pipeline {
agent any

options {
// Timeout counter starts AFTER agent is allocated
timeout(time: 1, unit: 'Minute')

environment {
salman_cred=credentials('3ec0ecef-0f8f-4c84-bdce-17c128860bdd')
}
stages {
stage('CALLCRED') {

steps {
echo "Username is $salman_cred"

## New
pipeline {
agent any

triggers {
cron('H */4 ** 1-5')

options {

timeout(time: 1, unit: 'Minute')
}
environment {
salman_cred=credentials('3ec0ecef-0f8f-4c84-bdce-17c128860bdd')
}
stages {
stage('CALLCRED') {

steps {
echo "Username is $salman_cred"
echo "Password is $salman_cred"
}
}
}


password
A password parameter, for example: parameters { password(name: 'PASSWORD', defaultValue: 'SECRET", description: 'A secret
passuord') }.

Example 10. Parameters, Declarative Pipeline

pipeline {
agent any
paraneters {
	string(mame: 'PERSON', defaultValue: 'Mr Jenkins', description: 'Who should I say hello to?')
	
	text(mame: 'BICGRAPHY', defaultValue: '', descriptiont 'Enter somc information about the person')
	
	booleanParam(mame: 'TOGGLE', defaultValue: true, description: 'Toggle this value')
	
	choice(name: 'CHOICE', choices: ['One', 'Two', 'Three"], description: 'Pick something' )
	
	password(mane: 'PASSWORD', defaultValue: 'SECRET', descriptiont 'Enter a password")

stages {
   stage('Example') {
      steps {
		 echo "Hello ${params. PERSON}"
		 
		 echo "Biography: $(parans.BIOGRAPHY}"
		 
		 echo "Toggle: $[params. TOGGLE]"
		 
		 echo "Choice: ${params.CHOICE}"
		 
		 echo "Password: ${params.PASSWCRD}"

=====================================================================================================================================================================


=====================================================================================================================================================================
# 09 Feb SUN - Jenkins

# MANAGE JENKINS -- crdentials set -- ID
Pipeline
environement
       { server_cred=credential("myserver_br") }
               scp -v ${server_cred}
               withcredetials0 $username

Link - https://www.jenkins.io/doc/book/pipeline/syntax/#agent

A typical example of a username password type credential (example from here) would look like:

withCredentials([usernamePassword(credentialsld: 'amazon', usernameVariable: 'USERNAME', passwordVariable: "PASSWORD')]) {
// available as an env variable, but will be masked if you try to print it out any which way
// note: single quotes prevent Groovy interpolation; expansion is by Bourne Shell, which is what you want
sh 'echo $PASSWORD'
// also available as a Groovy variable
echo USERNAME
// or inside double quotes for string interpolation
echo "username is $USERNAME"

# PARAMETERS ---- Diretcive
string paramaeter
choice parameter
boolean
text
password

# parameters (string(name: 'serv_ip', defaultValue: 'localhost', description: 'Plaese enter server ip ?) }

pipeline {
agent any

stages {

 stage ('runplay') {
 steps

  sh '''
  
  ansible-playbook test.yml -i $server_ip
     '''
}
}
}
}

## PreDefinded vairables in Jenkins OR Use Link ##
pipeline {
  agent any

stages

   stage (runplay') {
      steps {
             env.BUILD_ID
             env.JOB_NAME
             env.JENKINS_HOME
            }
}
}
}


The following variables are available to shell and batch build steps:

BRANCH NAME
For a multibranch project, this will be set to the name of the branch being built, for example in case you wish to deploy to production from master but not from feature branches; if corresponding
to some kind of change request, the name is generally arbitrary (refer to CHANGE_ID and CHANGE_TARGET).
BRANCH_IS_PRIMARY
For a multibranch project, if the SCM source reports that the branch being built is a primary branch, this will be set to "true"; else unset. Some SCM sources may report more than one branch as a
primary branch while others may not supply this information.
CHANGE_ID
For a multibranch project corresponding to some kind of change request, this will be set to the change ID, such as a pull request number, if supported: else unset.
CHANGE_URL
For a multibranch project corresponding to some kind of change request, this will be set to the change URL, if supported; else unset.
CHANGE TITLE
For a multibranch project corresponding to some kind of change request, this will be set to the title of the change, if supported; else unset.
CHANGE AUTHOR
For a multibranch project corresponding to some kind of change request, this will be set to the username of the author of the proposed change, if supported; else unset.
CHANGE_AUTHOR_DISPLAY_NAME
For a multibranch project corresponding to some kind of change request, this will be set to the human name of the author, if supported; else unset.
CHANGE AUTHOR_EMAIL
For a multibranch project corresponding to some kind of change request, this will be set to the email address of the author, if supported; else unset.
CHANGE_TARGET
For a multibranch project corresponding to some kind of change request, this will be set to the target or base branch to which the change could be merged, if supported; else unset.
CHANGE_BRANCH
For a multibranch project corresponding to some kind of change request, this will be set to the name of the actual head on the source control system which may or may not be different from
BRANCHI_NAME. For example in GitHub or Bitbucket this would have the name of the origin branch whereas BRANCH_NAME would be something like PR-24.
CHANGE_FORK
For a multibranch project corresponding to some kind of change request, this will be set to the name of the forked repo if the change originates from one; else unset.
TAG NAME
...

## When

- Acts like if condition to decide whether to run the particular stage or not as an optional block.
pipeline {
agent any
stages {
stage('build') {
when {
branch 'dev'
}
steps {
echo "Working on dev branch"
}
}
}
}


# Example

when expression
{BRANCH_NAME == /(production|staging)/}


pipeline {
agent any
stages {
stage('Example Build') {
steps {
echo 'Hello World'

}

}
stage('Example Deploy') {
when {
expression { BRANCH_NAME ==~ /(production| staging)/ }
anyof {
environment name: 'DEPLOY_TO', value: 'production'
environment name: 'DEPLOY_TO', value: 'staging'

}
steps {
echo 'Deploying'
}x4


# Example

stage ('runplay') {
when {
branch 'dev'
}
steps {
}
post {
success {
sh '''      ## To give for using scripting.
cp war $tomcat && echo file copied
   '''
}
success {
echo "I am running because the job ran successfully"
}x2


# Freestyle Vs Pipeline
- Freestyle
pipeline it is not a code
GIT
BUILD STEP
POST

- Pipeline
pipeline as a code
write jenkins

pipeline {
agent any
stages {
stage('build') {
steps {
script {
def skipBuild=env.SKIP_BUILD
if (skipBuild == null || skipBuild.isEmpty()) {
echo 'starting build ...'
} else {
echo 'skipping build ... '
}x6


# Example
pipeline {
agent any

stages {
stage('Check and Create Directory) {
steps {
script {
// Define the directory path
def dirPath = "test5'

// Check if the directory exists

if (!fileExists(dirPath)) {

sh "mkdir -p ${dirPath}"
echo "Directory created: ${dirPath}"
}else {
echo "Directory already exists: $(dirPath)"
}
}
}
}
}
}

## JENKISN INTERVIEW QS ##

1. jenkis freestyle vs pipeline
2. whats is pipeline as a code - explain
3. whats is paramaters and give 34 types
4. what is shared libarary
5. Diff between poll scm vs webhook
6. Scripted vs declarative pipeline
7. jenkisn load distribution - HOW TO
8. How to manage artifact in jenkins
9. Blue green deployment in jenkins
10. Build ocen and how to monitor jenkins

# To create user
-- Mange jenkins - users - Give name etc

-- Manage jenkins - Security - Security Give = LDAP etc.
   Authorization = Matrix-based security. And give assign to users.


=====================================================================================================================================================================





----------------------------------------------------------------------------------
# 14 Feb Fri 25 - Recording Not Avaiable in PC.
Topic : K8s Cluster Reset and Token Management
----------------------------------------------------------------------------------



=====================================================================================================================================================================
# 15 Feb SAT - Jenkins

# How to assign admin acces to a normal user. 

# If mistakley remove all Adminsiter rights, so we can add by command line and config.xml, user in file. 
 # If we change from command line then required Jenkins restart, but not required in case of GUI because it's call through using APIs. 
- cd /var/lib/jenkins/users/
- ls # For all users have folder in that inside there's config.xml we can see separately. 
- Add Administer or disability in /var/lib/jenkins/congog.xml file in security paragraph. 

Jenkins - Mange Jenkins - security - use Authorization matrix based. 
read-only is mandatory for all users, to login in Jenkins. 


## Description in simple words.
create a Item role
 rolename ----
 give rights (build create view )
 Attach job pattern -- (which job this role can access)
Assign Roles
 Attach / add user to created role.
 
 
# How to give project base access. 
Role Based Access Control ( RBAC) 
 - To give the access of Jenkins for developer. 
     Mange Jenkins - security --> 
  Authorization = Role Based Strategy ( If not showing, simply download plugins respectively RoleBased Authorization Strategy. --> Save. 

 Then : Mange Jenkins --> Manage and Assign Roles --> 
For create Roles. 
1. Global Rules
  Role-to-admin

2. Item Roles
  Role to add - name = role-qa-1
  Pattern = pharam* # for all pharam and single * means for al projects.
  role-dev-2, finance project. 
  And give respectively permission. 
  Save 
3. Agent Roles
   Its like slave, but not exact same it's use only for run the jobs. 


In Left side : Assign Roles
For assign roles. 

1. Global Roles
  Add user and assign permission for global. 
2. Item Roles
   Add user = Harry and select role-dev-2 option
   Add user = Shamu and select role-qa-1
Save


IQ : If job take too much time. 
- Then using parallel stage so it's runs parallely. And for Ram, CPU problm use vertical scaling to increase them. 
- For load issue create horizontal scaling agent to distrubed the load like master and slave. 


## Jenkins Agent:
 - No need to Install jenkins in agent server. 
 - Just run install openjdk and jars. 
 - Run instructions given by Jenkins Master Server. 
 - Using jar files agent will connect at Jenkins server. 
 - Agent could windows, docker, Linux systems
  Examples:
pipeline
agent any # For random and decided by master, depends on load. 
agent none
label agent-1 # for specific agent and for specific stages in script


-- Mange Jenkins --> Nodes --> New Node --> 
Name = Slave-Agent-Node-1 --> Select = permanent. 
( Copy means using form another existing system). 
Create. 
  - No. Of nodes = 1 or 2.
  - Remote root dict = /opt/
  - Labels = slave-lb-1p
    Or more three options. 
Save. 
   It is created like a template, Now double click on this newly created template and see how to set-up. 
Run that command and required prerequisite Java in that servers
- Install Java
- curl -so http://54.81.75.19:8080/jnlpJars/agent.jar
- java -jar agent.jar -url http://54.81.75.19:8080/ -secret 29a3fe801e70a10e61BBae8caf57deda6bd884822454cfebd8660954637200be -name "slave-node-agent-1" -webSocket -workDir "/opt/"


## Sample Script for Agent servers uses.

Link - stackoverflow.com/questions/43321026/can-i-define-multiple agent-labels-in-a-declarative jenkine pipdline
pipeline {
     agent none
     stages {
       stage('Build') {
          agent any
          steps {
             checkout scm
             sh 'make'
             stash includes: ' ** /target/ *. jar', name: 'app'
     }
     stage('Test on Linux') {
        agent {
          Label 'linux'
     }
     steps {
        unstash 'app"
        sh 'make check'
     }
     post {
        always {
            junit ' ** /target/ *. xml'
     }
     }
     }
     stage('Test on Windows') {
        agent {
          label 'windows'


## For GitOps Script

stages:
  - validate
  - security scans
  - unit test
  - functional test
  - build frontend
  - check or create ecr
  - build backend
  - scan container images
  - change schema
  - deploy or destroy app
  - code_quality_check

workflow:
auto_cancel:
on new commit: interruptible
workflow:
  auto_cancel:
    on new commit: interruptible
  rules:
    - if: $CI_PIPELINE_SOURCE == 'merge_request_event'
    when: always
    - if: ( $CI_COMMIT_BRANCH == "develop" | | $CI_COMMIT_BRANCH == "uat" | | $CI_COMMIT_BRANCH == "staging" | | $CI_COMMIT_BRANCH == "master" | | $CI_COMMIT_BRANCH =~ "/^feature\/*/" )
    - changes:
        - api/json/model.yaml

include:
  - template: Jobs/SAST.gitlab-ci.yml
  - template: Security/SAST-IaC.gitlab-ci.yml
  - template: Jobs/Secret-Detection.gitlab-ci.yml
  - template: Jobs/Container-Scanning.gitlab-ci.yml
  - template: Jobs/Code-Quality.gitlab-ci.yml

default:
  interruptible: true
	
=====================================================================================================================================================================

=====================================================================================================================================================================
# 16 Feb SUN- Git Explanation, Last Hour pending

# Diagram of ARCHITECTURE
Path:
"C:\Users\Dell\Desktop\IPM_CMDS\SS\SS_7__16-02-25.png"
"C:\Users\Dell\Desktop\IPM_CMDS\SS\SS_8__16-02-25.png"

=====================================================================================================================================================================

=====================================================================================================================================================================
# 22 Feb SAT- Promethus-Graffana Explanation


I am DevOps Engineer, I run pipeline in jenkins, I use declerivate amd scripted pipeline .
In my company, there is process we use PR process , developers create features and multiple branches. They are add new code in feature branches.And push the code in remote repository 
In one project github and other one is bigbucket and gitlab which runs in AWS DevOps. They push the code after they raised  PR request from the remote repository. And PR request is approved by 2-3 approvals form my senior teams. As soon as code approve 
We have configured webhook trigger from remote repository from git. Then comes and clone the remote repository first initional clone the code and then second time it goes the fetch the code, when new PR is approved. And run the pipelines, we have mentioned multiple stages, first stage is git clone , and second stage it's just copy the code in Tomcat server or nginx server.
Or once project is no java so directly push to nginx server. And nginx server code is copied and reflect to the production server for the end user code is reflected. 


Git explanation 
Prometheus grafana explanation and installation.

What is Prometheus?
Prometheus is a popular open-source monitoring and alerting system written in Golang, capable of collecting and
processing metrics from various targets. You can also query, view, analyse the metrics and get alerted based on the
thresholds.

Promethus ...

You are here: Home / Prometheus / Prometheus Monitoring: Features, Components, Architecture, and Metrics
Prometheus Monitoring: Features, Components, Architecture, and Metrics

The most effective organizations use metrics to track and comprehend the performance of their infrastructure and
applications. One of the most well-known time series databases (TSDB) today is the Prometheus monitoring platform.

In this blog we are going to learn about Prometheus Monitoring:
What is Prometheus?
Features of Prometheus
Prometheus Components
Prometheus Architecture
What are metrics?
- Metrics calucalte measures.

Conclusion
What is Prometheus?
Prometheus is a monitoring tool for capturing and processing any time-series that contains only numbers. Along with metrics, individual identifiers, and timestamps, it
collects, arranges, and stores them.
Key Components of Prometheus Architecture

Prometheus Server: The core component responsible for data collection, storage, querying, and alerting.
Time Series Database (TSDB): Stores time-series data efficiently, enabling fast querying and analysis of metrics.
Data Model: Defines how metrics are organized using metric names, labels, and values.
Exporters: These are tools that expose metrics from third-party systems as Prometheus metrics. Since Prometheus can only scrape metrics in its
Service Discovery: services are identified which are need to scraped.
Alert Manager: Handles alerts sent by the Prometheus server. It is responsible for deduplicating, grouping, and routing them to the correct receiver such as email,
PagerDuty, or OpsGenie. It also takes care of silencing and inhibition of alerts.
Pushgateway: A middleware component that accepts metrics from jobs that cannot be scraped. This is typical for short-lived jobs or batch jobs that don't expose an HTTP
endpoint long enough for Prometheus to scrape. Metrics are pushed to the Pushgateway, and then Prometheus scrapes the Pushgateway to collect these metrics.
Targets: Any system or service that exposes metrics via an HTTP endpoint. This could be applications, infrastructure components, or external services.
Client Libraries: Libraries for instrumenting applications and services to expose their own metrics in a Prometheus-compatible format.
PromQL: The query language used to query and analyze metrics stored in Prometheus.
Visualization Tools: Various tools and dashboards can be used to visualize the metrics collected by Prometheus, such as Grafana.

# What is promethus
Prometheus is a popular open-source monitoring and alerting system written in Golang,
capable of collecting and processing metrics from various targets. You can also query, view, analyse the metrics and get alerted based on the thresholds.
promethus - for metrics to track uses well-known time series databases (TSDB).

Key Components of Prometheus Architecture:

1. Prometheus Server. The core component responsible for data collection, storage, querying, and alerting.
2. Time Series Database (TSDB): Stores time-series data efficiently, enabling fast querying and analysis of metrics.
3. Data Model: Defines how metrics are organized using metric names, labels, and values
4. Exporters: These are tools that expose metrics from third-party systems as Prometheus metrics. Since Prometheus can only scrape metrics in its
5. Service Discovery: services are identified which are need to scraped.
6. Alert Manager: Handles alerts sent by the Prometheus server. It is responsible for deduplicating, grouping, and routing them to the correct receiver such as email, PagerDuty, or OpsGenie. It also takes care of silencing and inhibition of alerts.
7. Pushgateway: A middleware component that accepts metrics from jobs that cannot be scraped. This is typical for short-lived jobs or batch jobs that don't expose an HTTP endpoint long enough for
Prometheus to scrape. Metrics are pushed to the Pushgateway, and then Prometheus scrapes the Pushgateway to collect these metrics.
8. Targets: Any system or service that exposes metrics via an HTTP endpoint. This could be applications, infrastructure components, or external services.
Client Libraries: Libraries for instrumenting applications and services to expose their own metrics in a Prometheus-compatible format.
9. PromQL: The query language used to query and analyze metrics stored in Prometheus.
10. Visualization Tools: Various tools and dashboards can be used to visualize the metrics collected by Prometheus, such as Grafana.

You are here: Home / Prometheus / Prometheus Monitoring: Features, Components, Architecture, and Metrics
Prometheus Monitoring: Features, Components, Architecture, and Metrics
The most effective organizations use metrics to track and comprehend the performance of their infrastructure and applications. One of the most well-known time series databases (TSDB) today is the Prometheus monitoring platform.

scraped --- > to pull the metrics
pulling the metrics

## DataDog --- is good for momtoring devops


## banner ka merge ----- > main (merge)
baner ------- > main
source ----- > target
                here
banner <----- git merge banner				
       ----->
	   pull
	   pull from the source branch
git checkout main (in target branch)
git merge banner

# Monitoring - -Centralized monitoring
1. Server -- Zabbix nagios
2. Dashboard -- report visualize
3. Thresold value --- RAM CPU HARDDISK -- 80% ----
4. Alert - Alrams ---- notify emaill sms --- etc

where to monitor
Clients - host
1. webserver                           2. Dbserver
1. agent install
2. Metrics configure
3. Metric s measure caluclate of each devices each software
4. Cpu metrics --- cpuload-1 cpucore metrics 2 cputhread -3
5. hdd metrics -- hdd metrics type -1 hdd - load io -- metrics -2
1000of metrics
Monitoring Server -- Pull from the agent in intervals -- 5min
                              every 5mins Server ----- > agent notify -
									                     agent --- run metrics run (what we have configured)
														 cpu + ram -- -run and load inform
                                                         server will pull the information and display in dashboard

## Promethus Server pull fast
very poor dashboard report -- as a text
inside alert threshold
Alerts -- configure
promethus.yml
--- add host
cofigure in yaml language
promql querry for pull the metrics
.
zabbix.cfg
name=vale
tag
file ---
agent 1928
.
promethus
-- node exporter install metrics
client are called target --- as -- > node exporter /metrics

Promethus is god for devops tools -- which is exceled
promethus ---- microservices -- containers --
promethus --- good nw throughput --- very less nw load
promethus -- no complex configurations
promethus ---- Promql use to fetch the metrics (promethus querry language) -- speed performance minute querries.
promql - - docker imaage -- corrupted or fine
promql ----- pod motnitor -- containers -- image --


#### Promethus Installation on ubuntu  ####

$$$$$$install Prometheus on Ubuntu$$$$$$4

# sudo apt update && sudo apt upgrade -y

# mkdir /etc/prometheus
# mkdir /var/lib/prometheus

cd /tmp
curl -s https://api.github.com/repos/prometheus/prometheus/releases/latest | grep browser_download_url | grep linux-amd64 | cut -d "" -f 4 |wget -qi -
tar xvf prometheus -*. tar.gz
cd prometheus -* /
# mv prometheus /usr/local/bin/
# mv promtool /usr/local/bin/
# mv prometheus.yml /etc/prometheus/
# mv consoles/ console_libraries//etc/prometheus/
# chown -R prometheus:prometheus /etc/prometheus /var/lib/prometheus
# chown prometheus:prometheus /usr/local/bin/prometheus /usr/local/bin/promtool

sudo tee /etc/systemd/system/prometheus.service > /dev/null «EOF
[Unit]
Description=Prometheus
Wants=network-online.target
After=network-online.target

[Service]
User=prometheus
Group=prometheus
Type=simple
ExecStart=/usr/local/bin/prometheus \\
  -- config.file=/etc/prometheus/prometheus.yml \\
  -- storage.tsdb.path=/var/lib/prometheus \\
  -- web.console.templates=/etc/prometheus/consoles \\
  -- web.console.libraries=/etc/prometheus/console libraries

[Install]
WantedBy=multi-user.target
EOF

# systemctl daemon-reload
# systemctl enable -- now prometheus
# systemctl status prometheus

# http://server-ip:9090

## To start manually without systemctl.
tar xvf prometheus -*. tar.gz
cd promethus/ promethus prg promehtus.yml
./promthus ---- # start ----- > RUN PORT -- 9090

#### Graffan Install ####
# apt-get install -y apt-transport-https software-properties-common wget
# mkdir -p /etc/apt/keyrings/
# wget -q-0 - https://apt.grafana.com/gpg.key | gpg -- dearmor | sudo tee /etc/apt/keyrings/grafana.gpg > /dev/null
# echo "deb [signed-by=/etc/apt/keyrings/grafana.gpg] https://apt.grafana.com stable main" | sudo tee -a /etc/apt/sources.list.d/grafana.list
# echo "deb [signed-by=/etc/apt/keyrings/grafana.gpg) https://apt.grafana.com beta main" | sudo tee -a /etc/apt/sources.list.d/grafana.list
# apt-get install grafana

http://IP:3000/

=====================================================================================================================================================================

=====================================================================================================================================================================
# 23 Feb SUN- Promethus-Graffana Installation & Nodejs code pipeline

Prometheus Port:9090

# vi promehtus.yml
In that we can target and IPs
static_configs:
  - targets: ["localhost:9090"]
  - targets: ["192.168.29.33:9090"]
  - targets: ["192.168.29.45:9090"]
OR
  - job_name: "agent-1
    static_configs:
      - targets: [192.168.29.245

Prometheus Metrics Type
Prometheus monitors four primary metric types:

https://k21academy.com/prometheus/prometheus-monitoring-an-introduction/
https://www.fosstechnix.com/prometheus-tutorial-for-beginners/
https://www.kozhuhds.com/blog/an-easy-look-at-prometheus-architecture/
https://devopscube.com/prometheus-architecture/
https://medium.com/@tech_18484/understand-prometheus-architecture-1ab83afd53b8

# systemctl daemon-reload
# systemctl enable -- now node exporter
# systemctl status node_exporter
# http://localhost:9100/


########################
# curl -LO
https://github.com/prometheus/alertmanager/releases/latest/download/alertmanager -*. linux-amd64. tar gz

# tar -xvf alertmanager -. linux-amd64.tar.gz #cd alertmanager -. linux-amd64
# mv alertmanager amtool /usr/local/bin/
# mv alertmanager.yml /etc/alertmanager/

cat << EOF | sudo tee /etc/systemd/system/alertmanager.service
[Unit]
Description=Alertmanager
Wants=network-online.target
After=network-online.target

[Service]
User=alertmanager
Group=alertmanager
Type=simple
ExecStart=/usr/local/bin/alertmanager \
  -- config.file=/etc/prometheus/alertmanager.yml \
  -- storage.path=/var/lib/alertmanager

[Install]
WantedBy=multi-user.target
EOF

# systemctl daemon-reload
# systemctl enable -- now alertmanager

# vi /etc/prometheus/prometheus.yml
alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - "localhost:9093"

rule_files:
  - "alert_rules.yml"
---------------------------------------------
touch /etc/prometheus/alert-rules.yml

vi /etc/prometheus/alert-rules.yml
groups:
  - name: example_alerts
    rules:
      - alert: InstanceDown
        expr: up == 0
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Instance {{ $labels.instance }} down"
          description: "Instance {{ $labels.instance }} has been down for more than 5 minutes."

 - name: node-alerts
    rules:
      - alert: NodeDown
        expr: up == 1
        for: 15s
        labels:
          severity: critical
        annotations:
          summary: "Node is down"
          description: "The target {{ $labels.instance }} is unreachable for more than 5 minutes."




# systemctl restart prometheus
#  systemctl restart alertmanager

# http://ip:9093/

# vi /etc/alertmanager/alertmanager.yml
global:
  resolve_timeout: 10s

route:
  receiver: "email-alert"
  repeat_interval: 2m  # ⬅️ Sends alert emails every 2 minutes
  group_wait: 10s      # ⬅️ Waits 10 seconds before sending first alert
  group_interval: 2m   # ⬅️ Groups alerts and resends every 2 minutes

receivers:
  - name: "email-alert"
    email_configs:
      - to: "tnew70723@gmail.com"
        from: "tnew70723@gmail.com"
        smarthost: "smtp.gmail.com:587"
        auth_username: "tnew70723@gmail.com"
        auth_password: "yswm iaxx qgdx nfal"  # Google App Password
        require_tls: true
        send_resolved: true

~



#  systemctl restart alertmanager
#  systemctl status alertmanager
																										 # 
nslookup smtp.gmail.com
echo "nameserver 8.8.8.8" >> /etc/resolv.conf



$$$$$$$$$$$$$$$
promtool check config /etc/prometheus/prometheus.yml
$$$$4444444$$$$$

$$$$$$$$$$4prometheus yml file$$$$$$$$$
vim prometheus.yml
# My global config
global:
scrape_interval: 15s # Set the scrape interval to every 15 seconds.
Default is 1 minute.
evaluation_interval: 15s # Evaluate rules every 15 seconds.

# Alertmanager configuration
alerting:
  alertmanagers:
    - static_configs:
        - targets:
            - "alertmanager:9093"
            - "127.0.0.1:9093"

# Load rules once and periodically evaluate them according to the global
'evaluation_interval'.
rule_files:
  - "alert_rules.yml" # Mention the rule file

# A scrape configuration containing exactly one endpoint to scrape:
scrape_configs:
    job_name: "prometheus"
	static configs:
	  - targets: ["localhost:9090", "192.168.0.104:9100"]

#######################

********Install Grafana************

# apt-get install -y apt-transport-https software-properties-common wget

# mkdir -p /etc/apt/keyrings/
# wget -q -0 - https://apt.grafana.com/gpg.key | gpg -- dearmor | sudo tee /etc/apt/keyrings/grafana.gpg > /dev/null

# echo "deb [signed-by=/etc/apt/keyrings/grafana.gpg]
https://apt.grafana.com stable main" | sudo tee -a /etc/apt/sources.list.d/grafana.list

# echo "deb [signed-by=/etc/apt/keyrings/grafana.gpg]
https://apt.grafana.com beta main" | sudo tee -a /etc/apt/sources.list.d/grafana.list

# apt-get install grafana
# http://ip:3000/


Grafana is a freeware, multi-platform analytics, and visualization solution. Irrespective of the data storage location, we
can explore, query, and visualize the data. It offers you the tools to transform your time-series database into excellent
visualization and graphs.

Organizations utilize Grafana to monitor their log and infrastructure analytics, largely to enhance their functional
effectiveness. Dashboards track events and users because they automate the management, viewing, and collection of
data.

Security Analysts, Developers, and Product Leaders use this data to make their decisions. If you want to learn more
about Grafana, Join our Grafana training. This tutorial discusses dashboard creation, environment configuration, and
more of Grafana.


#what is grafana
- we can explore, query, and visualize the data. 
Transform your time-series database into excellent visualization and graphs
Grafana is a database monitoring and analysis tool.
It enables us to build dashboards visualizations of the essential measures

Grafana components
Data source --
creating dashboards
panel plugin --- install and visualize data i nvarious ways
grafana queries 26 querries per panel support
grafana queery language -- prompql + Sql + InfluxQL + postgress

Grafana Dashboards to visualize the data while the backend is controlled by the Prometheus
Variables in Grafana enable dynamic dashboards, allowing you to select different instances of metrics

in p anel
Adding a row

A row is a logical divider within a dashboard that groups panels together.
Time intervals and automatic refresh
Alerting
dashboard import and export


## IQ Webserver Nginx and Apache differnce between
      If nodejs can run independently.
	  
https://youtu.be/Fil8uO7Mw1A?si=tFm5-QIRGYYUwzZb
https://github.com/RAJANI9/boxtuse-sample-java-war-hello/blob/master/Jenkinsprojectfile


=====================================================================================================================================================================

=====================================================================================================================================================================
# 01 Mar SAT- Devops Project Agile and Jira Explanation

Use below pipeline script:
Path:
"C:\Users\Dell\Desktop\IPM_CMDS\SS\pipeline-tomcat.txt"
"C:\Users\Dell\Desktop\IPM_CMDS\SS\Node js on nginx server.txt"


## Defination ##
Deploy:
After a build passes the testing phase, it becomes a candidate for deployment.
There are two main ways to deploy the build, including:
- Continuous delivery-the build is sent to human staff for approval and then deployed. For example, new versions are automatically deployed to a test environment, but promotion to production is gated by a manual approval or merge request.
- Continuous deployment-the pipeline automatically deploys the build to testing, staging, and production environments, assuming it passes all relevant tests, with no manual approvals.

A typical deployment phase creates a deployment environment and moves the build to a deployment target, like a server. You can automate these steps with scripts or workflows in automation tools. Most deployments also integrate with error reporting and ticketing tools to detect unexpected errors post-deployment and alert developers.


## Types of Deployment ##
1. Bridge --- WATER FALL MODEL
 ~ --> Requirements --> Design --> Implemenation --> Verfication --> Maintance. # Architecture (2006)
2. AGILE --- PROCESS - PROJECT MANAGER

BIG LARGE - small code --- create - -deploy -- paralley features.
Code build wiht small piece of code and deployed andparallely features code is updated frequently.

JIRA --- Project
management --- provisions good agile methodolgy

YOU
PROJECt IS ASSGINED TO YOU Jira ticket RAISE
AGILE SPRINT -1a -- 2weeks


##  AGILE COMPONENTS  ##
1. SPRINT
2. Sprint Planning meeting
3. PI -- Program increment planning
4. Daily Standup Meeting -
5. Sprint Retrosepctive meeting
6. Story Point
7. Epic
8. Scrum master
9. Spike
10. Zero sprint
11. velocity

AGILE ---- COMPONENTS USE WITH - JIRA PROJECT MANAGEMENT and jir a ticketing tool.

AGILE Methodology
Set of Practices - following properly and requirement can be change in any time
How ticket is assigned and give regular updates and take updates.

Sprint : is just a cylce in time interval - task to be completed -- how much work to be completed
2 week is one sprint - somethimes 3 weeks what need to be

Sprint Planning meeting
You define all the things like what all things will be done and delivered in this sprint

PI -- Program increment planning - Big larger Sprint - deliver in a quarter --- as in one year -4 Pl in one year comes 6 sprints
Pi planinng acrros the teams and sprint planning accross the teammates.

Daily Standup Meeting -
What wroked yesterday and what work today lead with scrum master - to take updates held most Daily morning meeting or evening discuss any issue.

Sprint Retrosepctive meeting -- held after sprint Completed what good and bad to improve discussed in this meeting.

Story Point --- task - depends on story point - 1 story point - 1day - and 1stroy point may be 2days.

Epic =--- Larege segment of stories in one sprint cannot be completed , so devided in particular stories.

Scrum master - any particular srpint or sprint planning the one who is leading is known as scrum master responsibel to monitor stories os each individual and take proper updates from them.

Zero Sprint - use before 1st srpint that interval is called zero sprint.
 
Spike - No Clarity - so not able to give a proper deadline and create stories (need time to research not decided and when this will complete.

Velocity -- particular team - chekc how muc amount of work done by this team.

# Git log #
Link: https://www.techtarget.com/scarchitoperations/answer/How-to-roll-back-Git-code-to-a-previous-commit  ## Not working

CODE -- - -ABC --- commit --- - v1 HEADid --- 5fr47
git log
CODE --- - ABCD - -commit -- 67843
git log
CODE -- ABCDFRG --- commit -3 HEAD-678954
Glt PUSH REMOTE GITHUB
GIT revert HEAD6783
ABCD -- EFG --- git push

=====================================================================================================================================================================
